2018-11-22 18:31:26,328 : INFO : Batch 1 of 15. Loss: 13.697
2018-11-22 18:31:27,024 : INFO : Batch 2 of 15. Loss: 5.871
2018-11-22 18:31:27,713 : INFO : Batch 3 of 15. Loss: 7.602
2018-11-22 18:31:28,397 : INFO : Batch 4 of 15. Loss: 10.817
2018-11-22 18:31:29,081 : INFO : Batch 5 of 15. Loss: 7.260
2018-11-22 18:31:29,767 : INFO : Batch 6 of 15. Loss: 7.394
2018-11-22 18:31:30,544 : INFO : Batch 7 of 15. Loss: 9.404
2018-11-22 18:31:31,255 : INFO : Batch 8 of 15. Loss: 7.932
2018-11-22 18:31:31,977 : INFO : Batch 9 of 15. Loss: 8.106
2018-11-22 18:31:32,721 : INFO : Batch 10 of 15. Loss: 4.643
2018-11-22 18:31:33,408 : INFO : Batch 11 of 15. Loss: 5.399
2018-11-22 18:31:34,111 : INFO : Batch 12 of 15. Loss: 4.092
2018-11-22 18:31:34,831 : INFO : Batch 13 of 15. Loss: 6.408
2018-11-22 18:31:35,568 : INFO : Batch 14 of 15. Loss: 7.604
2018-11-22 18:31:36,275 : INFO : Batch 15 of 15. Loss: 5.659
2018-11-22 18:31:40,045 : INFO : Done epoch 0. Validation accuracy: 74.5% Training accuracy: 74.4% 
2018-11-22 18:31:51,204 : INFO : Batch 1 of 15. Loss: 3.920
2018-11-22 18:31:51,913 : INFO : Batch 2 of 15. Loss: 7.311
2018-11-22 18:31:52,614 : INFO : Batch 3 of 15. Loss: 2.209
2018-11-22 18:31:53,302 : INFO : Batch 4 of 15. Loss: 4.613
2018-11-22 18:31:53,989 : INFO : Batch 5 of 15. Loss: 5.435
2018-11-22 18:31:54,672 : INFO : Batch 6 of 15. Loss: 5.271
2018-11-22 18:31:55,356 : INFO : Batch 7 of 15. Loss: 3.727
2018-11-22 18:31:56,047 : INFO : Batch 8 of 15. Loss: 3.369
2018-11-22 18:31:56,745 : INFO : Batch 9 of 15. Loss: 3.351
2018-11-22 18:31:57,434 : INFO : Batch 10 of 15. Loss: 4.844
2018-11-22 18:31:58,128 : INFO : Batch 11 of 15. Loss: 2.891
2018-11-22 18:31:58,818 : INFO : Batch 12 of 15. Loss: 3.746
2018-11-22 18:31:59,505 : INFO : Batch 13 of 15. Loss: 2.932
2018-11-22 18:32:00,200 : INFO : Batch 14 of 15. Loss: 3.517
2018-11-22 18:32:00,885 : INFO : Batch 15 of 15. Loss: 4.688
2018-11-22 18:32:03,547 : INFO : Done epoch 1. Validation accuracy: 82.7% Training accuracy: 82.1% 
2018-11-22 18:32:14,646 : INFO : Batch 1 of 15. Loss: 2.611
2018-11-22 18:32:15,345 : INFO : Batch 2 of 15. Loss: 3.421
2018-11-22 18:32:16,040 : INFO : Batch 3 of 15. Loss: 1.550
2018-11-22 18:32:16,731 : INFO : Batch 4 of 15. Loss: 1.638
2018-11-22 18:32:17,425 : INFO : Batch 5 of 15. Loss: 4.752
2018-11-22 18:32:18,119 : INFO : Batch 6 of 15. Loss: 2.731
2018-11-22 18:32:18,813 : INFO : Batch 7 of 15. Loss: 2.655
2018-11-22 18:32:19,500 : INFO : Batch 8 of 15. Loss: 3.887
2018-11-22 18:32:20,189 : INFO : Batch 9 of 15. Loss: 5.135
2018-11-22 18:32:20,885 : INFO : Batch 10 of 15. Loss: 2.408
2018-11-22 18:32:21,577 : INFO : Batch 11 of 15. Loss: 1.853
2018-11-22 18:32:22,266 : INFO : Batch 12 of 15. Loss: 1.586
2018-11-22 18:32:22,950 : INFO : Batch 13 of 15. Loss: 2.632
2018-11-22 18:32:23,637 : INFO : Batch 14 of 15. Loss: 3.737
2018-11-22 18:32:24,323 : INFO : Batch 15 of 15. Loss: 2.159
2018-11-22 18:32:27,799 : INFO : Done epoch 2. Validation accuracy: 77.4% Training accuracy: 77.1% 
2018-11-22 18:32:28,615 : INFO : Batch 1 of 15. Loss: 1.873
2018-11-22 18:32:29,438 : INFO : Batch 2 of 15. Loss: 2.406
2018-11-22 18:32:30,261 : INFO : Batch 3 of 15. Loss: 2.603
2018-11-22 18:32:31,077 : INFO : Batch 4 of 15. Loss: 3.751
2018-11-22 18:32:31,898 : INFO : Batch 5 of 15. Loss: 4.139
2018-11-22 18:32:32,720 : INFO : Batch 6 of 15. Loss: 1.104
2018-11-22 18:32:33,581 : INFO : Batch 7 of 15. Loss: 6.493
2018-11-22 18:32:34,401 : INFO : Batch 8 of 15. Loss: 2.813
2018-11-22 18:32:35,227 : INFO : Batch 9 of 15. Loss: 1.858
2018-11-22 18:32:36,048 : INFO : Batch 10 of 15. Loss: 2.119
2018-11-22 18:32:36,879 : INFO : Batch 11 of 15. Loss: 4.168
2018-11-22 18:32:37,700 : INFO : Batch 12 of 15. Loss: 2.333
2018-11-22 18:32:38,521 : INFO : Batch 13 of 15. Loss: 1.739
2018-11-22 18:32:39,349 : INFO : Batch 14 of 15. Loss: 3.082
2018-11-22 18:32:40,167 : INFO : Batch 15 of 15. Loss: 2.399
2018-11-22 18:32:43,715 : INFO : Done epoch 3. Validation accuracy: 75.5% Training accuracy: 77.6% 
2018-11-22 18:32:44,537 : INFO : Batch 1 of 15. Loss: 1.501
2018-11-22 18:32:45,362 : INFO : Batch 2 of 15. Loss: 0.772
2018-11-22 18:32:46,178 : INFO : Batch 3 of 15. Loss: 3.959
2018-11-22 18:32:46,991 : INFO : Batch 4 of 15. Loss: 2.232
2018-11-22 18:32:47,806 : INFO : Batch 5 of 15. Loss: 1.644
2018-11-22 18:32:48,614 : INFO : Batch 6 of 15. Loss: 0.610
2018-11-22 18:32:49,430 : INFO : Batch 7 of 15. Loss: 1.532
2018-11-22 18:32:50,243 : INFO : Batch 8 of 15. Loss: 2.393
2018-11-22 18:32:51,059 : INFO : Batch 9 of 15. Loss: 2.033
2018-11-22 18:32:51,870 : INFO : Batch 10 of 15. Loss: 2.496
2018-11-22 18:32:52,681 : INFO : Batch 11 of 15. Loss: 2.622
2018-11-22 18:32:53,494 : INFO : Batch 12 of 15. Loss: 1.746
2018-11-22 18:32:54,318 : INFO : Batch 13 of 15. Loss: 2.065
2018-11-22 18:32:55,145 : INFO : Batch 14 of 15. Loss: 1.124
2018-11-22 18:32:56,013 : INFO : Batch 15 of 15. Loss: 0.868
2018-11-22 18:32:59,599 : INFO : Done epoch 4. Validation accuracy: 83.2% Training accuracy: 85.4% 
2018-11-22 18:33:10,904 : INFO : Batch 1 of 15. Loss: 1.161
2018-11-22 18:33:11,616 : INFO : Batch 2 of 15. Loss: 0.676
2018-11-22 18:33:12,316 : INFO : Batch 3 of 15. Loss: 1.706
2018-11-22 18:33:13,025 : INFO : Batch 4 of 15. Loss: 0.852
2018-11-22 18:33:13,716 : INFO : Batch 5 of 15. Loss: 2.090
2018-11-22 18:33:14,412 : INFO : Batch 6 of 15. Loss: 0.727
2018-11-22 18:33:15,106 : INFO : Batch 7 of 15. Loss: 1.738
2018-11-22 18:33:15,800 : INFO : Batch 8 of 15. Loss: 1.912
2018-11-22 18:33:16,486 : INFO : Batch 9 of 15. Loss: 0.514
2018-11-22 18:33:17,175 : INFO : Batch 10 of 15. Loss: 1.735
2018-11-22 18:33:17,862 : INFO : Batch 11 of 15. Loss: 0.415
2018-11-22 18:33:18,550 : INFO : Batch 12 of 15. Loss: 1.589
2018-11-22 18:33:19,236 : INFO : Batch 13 of 15. Loss: 1.370
2018-11-22 18:33:19,934 : INFO : Batch 14 of 15. Loss: 1.594
2018-11-22 18:33:20,627 : INFO : Batch 15 of 15. Loss: 2.097
2018-11-22 18:33:24,193 : INFO : Done epoch 5. Validation accuracy: 75.0% Training accuracy: 82.9% 
2018-11-22 18:33:25,028 : INFO : Batch 1 of 15. Loss: 1.150
2018-11-22 18:33:25,851 : INFO : Batch 2 of 15. Loss: 1.573
2018-11-22 18:33:26,686 : INFO : Batch 3 of 15. Loss: 0.921
2018-11-22 18:33:27,518 : INFO : Batch 4 of 15. Loss: 1.067
2018-11-22 18:33:28,352 : INFO : Batch 5 of 15. Loss: 1.399
2018-11-22 18:33:29,171 : INFO : Batch 6 of 15. Loss: 1.176
2018-11-22 18:33:29,991 : INFO : Batch 7 of 15. Loss: 2.199
2018-11-22 18:33:30,812 : INFO : Batch 8 of 15. Loss: 1.220
2018-11-22 18:33:31,629 : INFO : Batch 9 of 15. Loss: 0.868
2018-11-22 18:33:32,443 : INFO : Batch 10 of 15. Loss: 1.735
2018-11-22 18:33:33,268 : INFO : Batch 11 of 15. Loss: 1.134
2018-11-22 18:33:34,091 : INFO : Batch 12 of 15. Loss: 0.519
2018-11-22 18:33:34,899 : INFO : Batch 13 of 15. Loss: 0.918
2018-11-22 18:33:35,708 : INFO : Batch 14 of 15. Loss: 1.030
2018-11-22 18:33:36,523 : INFO : Batch 15 of 15. Loss: 0.280
2018-11-22 18:33:40,066 : INFO : Done epoch 6. Validation accuracy: 83.7% Training accuracy: 85.5% 
2018-11-22 18:33:49,786 : INFO : Batch 1 of 15. Loss: 0.928
2018-11-22 18:33:50,491 : INFO : Batch 2 of 15. Loss: 2.314
2018-11-22 18:33:51,197 : INFO : Batch 3 of 15. Loss: 3.563
2018-11-22 18:33:51,937 : INFO : Batch 4 of 15. Loss: 1.639
2018-11-22 18:33:52,633 : INFO : Batch 5 of 15. Loss: 1.182
2018-11-22 18:33:53,338 : INFO : Batch 6 of 15. Loss: 1.289
2018-11-22 18:33:54,040 : INFO : Batch 7 of 15. Loss: 1.777
2018-11-22 18:33:54,734 : INFO : Batch 8 of 15. Loss: 1.599
2018-11-22 18:33:55,434 : INFO : Batch 9 of 15. Loss: 1.888
2018-11-22 18:33:56,153 : INFO : Batch 10 of 15. Loss: 1.691
2018-11-22 18:33:56,868 : INFO : Batch 11 of 15. Loss: 1.585
2018-11-22 18:33:57,576 : INFO : Batch 12 of 15. Loss: 1.520
2018-11-22 18:33:58,319 : INFO : Batch 13 of 15. Loss: 1.685
2018-11-22 18:33:59,078 : INFO : Batch 14 of 15. Loss: 1.173
2018-11-22 18:33:59,788 : INFO : Batch 15 of 15. Loss: 1.395
2018-11-22 18:34:03,380 : INFO : Done epoch 7. Validation accuracy: 70.7% Training accuracy: 74.8% 
2018-11-22 18:34:04,286 : INFO : Batch 1 of 15. Loss: 1.675
2018-11-22 18:34:05,125 : INFO : Batch 2 of 15. Loss: 2.087
2018-11-22 18:34:05,978 : INFO : Batch 3 of 15. Loss: 1.224
2018-11-22 18:34:06,806 : INFO : Batch 4 of 15. Loss: 1.484
2018-11-22 18:34:07,639 : INFO : Batch 5 of 15. Loss: 1.657
2018-11-22 18:34:08,459 : INFO : Batch 6 of 15. Loss: 1.399
2018-11-22 18:34:09,273 : INFO : Batch 7 of 15. Loss: 2.491
2018-11-22 18:34:10,089 : INFO : Batch 8 of 15. Loss: 1.135
2018-11-22 18:34:10,941 : INFO : Batch 9 of 15. Loss: 2.043
2018-11-22 18:34:11,787 : INFO : Batch 10 of 15. Loss: 0.840
2018-11-22 18:34:12,620 : INFO : Batch 11 of 15. Loss: 1.253
2018-11-22 18:34:13,444 : INFO : Batch 12 of 15. Loss: 0.898
2018-11-22 18:34:14,264 : INFO : Batch 13 of 15. Loss: 1.554
2018-11-22 18:34:15,075 : INFO : Batch 14 of 15. Loss: 1.469
2018-11-22 18:34:15,897 : INFO : Batch 15 of 15. Loss: 0.671
2018-11-22 18:34:19,425 : INFO : Done epoch 8. Validation accuracy: 73.6% Training accuracy: 80.8% 
2018-11-22 18:34:20,242 : INFO : Batch 1 of 15. Loss: 0.889
2018-11-22 18:34:21,097 : INFO : Batch 2 of 15. Loss: 1.470
2018-11-22 18:34:21,916 : INFO : Batch 3 of 15. Loss: 1.008
2018-11-22 18:34:22,742 : INFO : Batch 4 of 15. Loss: 1.464
2018-11-22 18:34:23,558 : INFO : Batch 5 of 15. Loss: 1.100
2018-11-22 18:34:24,368 : INFO : Batch 6 of 15. Loss: 0.821
2018-11-22 18:34:25,184 : INFO : Batch 7 of 15. Loss: 1.464
2018-11-22 18:34:25,993 : INFO : Batch 8 of 15. Loss: 0.849
2018-11-22 18:34:26,822 : INFO : Batch 9 of 15. Loss: 1.103
2018-11-22 18:34:27,638 : INFO : Batch 10 of 15. Loss: 1.338
2018-11-22 18:34:28,464 : INFO : Batch 11 of 15. Loss: 1.344
2018-11-22 18:34:29,322 : INFO : Batch 12 of 15. Loss: 0.881
2018-11-22 18:34:30,196 : INFO : Batch 13 of 15. Loss: 1.051
2018-11-22 18:34:31,089 : INFO : Batch 14 of 15. Loss: 0.762
2018-11-22 18:34:31,918 : INFO : Batch 15 of 15. Loss: 1.403
2018-11-22 18:34:35,524 : INFO : Done epoch 9. Validation accuracy: 76.9% Training accuracy: 83.7% 
2018-11-22 18:34:36,349 : INFO : Batch 1 of 15. Loss: 0.709
2018-11-22 18:34:37,169 : INFO : Batch 2 of 15. Loss: 0.777
2018-11-22 18:34:38,004 : INFO : Batch 3 of 15. Loss: 1.572
2018-11-22 18:34:38,865 : INFO : Batch 4 of 15. Loss: 0.735
2018-11-22 18:34:39,689 : INFO : Batch 5 of 15. Loss: 0.853
2018-11-22 18:34:40,507 : INFO : Batch 6 of 15. Loss: 0.963
2018-11-22 18:34:41,316 : INFO : Batch 7 of 15. Loss: 0.915
2018-11-22 18:34:42,156 : INFO : Batch 8 of 15. Loss: 1.574
2018-11-22 18:34:42,992 : INFO : Batch 9 of 15. Loss: 0.573
2018-11-22 18:34:43,815 : INFO : Batch 10 of 15. Loss: 1.414
2018-11-22 18:34:44,624 : INFO : Batch 11 of 15. Loss: 0.873
2018-11-22 18:34:45,438 : INFO : Batch 12 of 15. Loss: 0.820
2018-11-22 18:34:46,251 : INFO : Batch 13 of 15. Loss: 0.729
2018-11-22 18:34:47,058 : INFO : Batch 14 of 15. Loss: 0.841
2018-11-22 18:34:47,869 : INFO : Batch 15 of 15. Loss: 0.698
2018-11-22 18:34:51,474 : INFO : Done epoch 10. Validation accuracy: 78.4% Training accuracy: 84.9% 
2018-11-22 18:34:52,299 : INFO : Batch 1 of 15. Loss: 0.745
2018-11-22 18:34:53,118 : INFO : Batch 2 of 15. Loss: 1.078
2018-11-22 18:34:53,964 : INFO : Batch 3 of 15. Loss: 1.038
2018-11-22 18:34:54,836 : INFO : Batch 4 of 15. Loss: 1.883
2018-11-22 18:34:55,685 : INFO : Batch 5 of 15. Loss: 1.357
2018-11-22 18:34:56,520 : INFO : Batch 6 of 15. Loss: 1.192
